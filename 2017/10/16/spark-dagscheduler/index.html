<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>spark_dagscheduler | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="基于 spark 1.6.2  面向 Stage 的调度器，负责计算每个 job 的 DAG，并将 DAG 图划分为不同的 stage，对哪些 RDD 以及相应输出进行记录，寻找一个运行相应 job 所需要的最小 stage。然后将 stage 以 TaskSet 的形式提交到下层的 TaskScheduler 进行具体的 task 调度。每个 TaskSet 包含整个可以独立运行的 task，">
<meta name="keywords" content="spark,stage,rdd,partition,dagscheduler,source_code">
<meta property="og:type" content="article">
<meta property="og:title" content="spark_dagscheduler">
<meta property="og:url" content="http://yoursite.com/2017/10/16/spark-dagscheduler/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="基于 spark 1.6.2  面向 Stage 的调度器，负责计算每个 job 的 DAG，并将 DAG 图划分为不同的 stage，对哪些 RDD 以及相应输出进行记录，寻找一个运行相应 job 所需要的最小 stage。然后将 stage 以 TaskSet 的形式提交到下层的 TaskScheduler 进行具体的 task 调度。每个 TaskSet 包含整个可以独立运行的 task，">
<meta property="og:image" content="http://yoursite.com/2017/10/16/images/procesure.jpg">
<meta property="og:image" content="http://yoursite.com/2017/10/16/spark-dagscheduler/images/procesure.jpg">
<meta property="og:updated_time" content="2017-11-18T13:28:20.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="spark_dagscheduler">
<meta name="twitter:description" content="基于 spark 1.6.2  面向 Stage 的调度器，负责计算每个 job 的 DAG，并将 DAG 图划分为不同的 stage，对哪些 RDD 以及相应输出进行记录，寻找一个运行相应 job 所需要的最小 stage。然后将 stage 以 TaskSet 的形式提交到下层的 TaskScheduler 进行具体的 task 调度。每个 TaskSet 包含整个可以独立运行的 task，">
<meta name="twitter:image" content="http://yoursite.com/2017/10/16/images/procesure.jpg">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-spark-dagscheduler" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/10/16/spark-dagscheduler/" class="article-date">
  <time datetime="2017-10-16T12:01:20.000Z" itemprop="datePublished">2017-10-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      spark_dagscheduler
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>基于 spark 1.6.2</p>
</blockquote>
<p>面向 Stage 的调度器，负责计算每个 job 的 DAG，并将 DAG 图划分为不同的 stage，对哪些 RDD 以及相应输出进行记录，寻找一个运行相应 job 所需要的最小 stage。然后将 <code>stage</code> 以 <code>TaskSet</code> 的形式提交到下层的 <code>TaskScheduler</code> 进行具体的 task 调度。每个 <code>TaskSet</code> 包含整个可以独立运行的 task，这些 task 能够利用集群上已有的数据立即运行起来，如果集群上已有的数据已经不存在了，那么当前 task 就会失败。</p>
<p>Spark 的 stage 以 RDD 的 shuffle 为界进行划分。窄依赖的 RDD 操作会被穿起来放到一个 task 中，比如 <code>map()</code>, <code>filter()</code> 这样的操作。但是需要使用到 shuffle 依赖的操作，需要多个 stage（至少一个将中间文件写到特定的地方，另外一个从特定的地方进行读取）。每个 Stage，只会对其他 Stage 有 shuffle 依赖，在同一个 stage 中会进行很多计算。实际的将计算串起来的操作在 RDD.compute 中完成。</p>
<p><code>DAGScheduler</code> 同样会基于缓存状态决定 task 希望运行在那（preferred location），如果 shuffle 输出文件丢失造成的 Stage 失败，会重新被提交。在 <strong>Stage 内部</strong> 的不是由 shuffle 文件丢失造成的失败，由 <code>TaskScheduler</code> 来完成，<code>TaskScheduler</code> 会在取消整个 stage 前进行小部分重试。<br><a id="more"></a><br>下面的几个核心概念：</p>
<ul>
<li>Jobs (通过 <code>ActiveJob</code> 来表示）是提交给调度器中最上次工作单元。比如，用户触发一次 action，比如 <code>count()</code>，的时候，就会提交一个 Job。每个 Job 可能会包含多个 stage</li>
<li>Stages 是 Job 中产生中间结果的一系列 Task 的集合，同一个 Stage 的每个 Task 运行着同样的逻辑，只是处理同一个 RDD 的不同分区。Stage 以 Shuffle 为界（后面的 Stage 必须等前面的 Stage 运行完才能继续往下进行）。现在有两种 Stage：<code>ResultStage</code>，Job 的最终执行 action 的 Stage，<code>ShuffleMapState</code> 产生中间文件的 shuffle。如果多 Job 公用同一个 RDD 的话，Stage 可能会在多个 Job 间共享。</li>
<li>Tasks 是组小的独立工作单元，每个 Task 会被独立的分发到具体的机器上运行</li>
<li>Cache tracking: <code>DAGScheduler</code> 会记录哪些 RDD 以及被缓存过，从而避免重复计算，也会记录哪些 Stage 已经生成过输出文件从而避免重复操作</li>
<li>Preferred locations: <code>DAGScheduler</code> 会根据计算所依赖的 RDD 数据、缓存的地址以及 shuffle 输出结果对 Task 进行调度</li>
<li>Cleanup: 如果上游依赖的 Job 处理完成后，下游的数据会被清理掉，防止长驻服务的内存泄漏</li>
</ul>
<p>为了能够从错误中进行恢复，同一个 Stage 可能会被运行多次，每一次就是一个 “attempts”。如果 <code>TaskScheduler</code> 汇报某个 task 失败的原因是因为依赖的前一个 Stage 的输出文件已经不见了，那么 <code>DAGScheduler</code> 会对前一个 Stage 重新进行提交。这通过 <code>CompletionEveent</code> 以及 <code>FetchFailed</code> 或者 <code>ExecutorLost</code> 事件来完成。<code>DAGScheduler</code> 会等待一小段时间来判断是否还有其他 task 需要重试，然后将所有失败的 task 进行重试。在这一过程中，我们需要重新对之前清理过的 Stage 进行计算。由于之前的 “attempt” 可能还在运行，所以需要特别注意</p>
<p><img src="../images/procesure.jpg" alt="processure"><br>kk<br><img src="images/procesure.jpg" alt="processure"></p>
<p>上面的图是 DAGScheduler.scala 的主题脉络，当然还包括其他诸如 <code>taskStarted</code>, <code>taskGettingResult</code>, <code>taskEnded</code>, <code>executorZHeatbeatReceived</code>, <code>executorLost</code>, <code>executorAdded</code>, <code>taskSetFailed</code>, 等函数</p>
<blockquote>
<p>其中带箭头的虚线为消息调用；带箭头的实线为直接调用，无箭头的实线表示方法申明和内部的主要实现（比如 <code>getShuffleMapStage</code> 中包括了 <code>getAncestorShuffleDependencies</code> 和 <code>newOrUsedShuffleStage</code>)</p>
</blockquote>
<h4 id="上面是注释，下面是代码解释"><a href="#上面是注释，下面是代码解释" class="headerlink" title="上面是注释，下面是代码解释"></a>上面是注释，下面是代码解释</h4><p>入口在 <code>runJob</code>，<code>runJob</code> 会调用 <code>submitJob(rdd, func, partitions, callSite, resultHandler, properties)</code> 返回一个 waiter，等待处理完成</p>
<p><code>submitJob</code> 核心代码如下，主要生成一个 waiter 对象，然后发送一个 <code>JobSubmitted</code> 信号</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">val func2 = func.asInstanceOf[(TaskContext, Iterator[_]) =&gt; _]</div><div class="line">val waiter = new JobWaiter(this, jobId, partitions.size, resultHandler)</div><div class="line">eventProcessLoop.post(JobSubmitted(jobId, rdd, func2, partitions.toArray, callSite, waiter, SerializationUtils.clone(properties)))</div></pre></td></tr></table></figure>
<p><code>JobSubmitted</code> 方法会将整个 DAG 图进行 Stage 的划分，然后提交 finalStage（也就是 action 所在的 Stage），其中 <code>newResultStage</code> 会进行具体的 Stage 划分，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">try &#123;</div><div class="line">	// New stage creation may throw an exception if, for example, jobs are run on a</div><div class="line">	// HadoopRDD whose underlying HDFS files have been deleted.</div><div class="line">	finalStage = newResultStage(finalRDD, func, partitions, jobId, callSite)</div><div class="line">&#125; catch &#123;</div><div class="line">	case e: Exception =&gt;</div><div class="line">		logWarning(&quot;Creating new stage failed due to exception - job: &quot; + jobId, e)</div><div class="line">		listener.jobFailed(e)</div><div class="line">		return</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>submitJob</code> 返回的 <code>JobWaiter</code>，JobWaiter 用于控制 Job，以及 Job 结束后进行相应的状态更新</p>
<p><code>newResultStage</code> 会将所有的 Stage 划分出来（通过 <code>getParentStagesAndId</code> 函数，<code>getParentStages</code> 进行具体的 Stage 划分），其中 <code>getParentStages</code> 进行 BFS 进行查找（这个地方 BFS 和 DFS 有什么区别？）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">private def getParentStages(rdd: RDD[_], firstJobId: Int): List[Stage] = &#123;</div><div class="line">	val parents = new HashSet[Stage]</div><div class="line">	val visited = new HashSet[RDD[_]]</div><div class="line">	// We are manually maintaining a stack here to prevent StackOverflowError</div><div class="line">	// caused by recursively visiting</div><div class="line">	val waitingForVisit = new Stack[RDD[_]]</div><div class="line">	def visit(r: RDD[_]) &#123;</div><div class="line">		if (!visited(r)) &#123;</div><div class="line">			visited += r</div><div class="line">			// Kind of ugly: need to register RDDs with the cache here since</div><div class="line">			// we can&apos;t do it in its constructor because # of partitions is unknown</div><div class="line">			for (dep &lt;- r.dependencies) &#123;</div><div class="line">				dep match &#123;</div><div class="line">					case shufDep: ShuffleDependency[_, _, _] =&gt;</div><div class="line">						parents += getShuffleMapStage(shufDep, firstJobId)</div><div class="line">					case _ =&gt;</div><div class="line">						waitingForVisit.push(dep.rdd)</div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	waitingForVisit.push(rdd)</div><div class="line">	while (waitingForVisit.nonEmpty) &#123;</div><div class="line">		visit(waitingForVisit.pop())</div><div class="line">	&#125;</div><div class="line">	parents.toList</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>getParentStages 返回某个 RDD 的所有依赖的 stage（直接和间接的），stage 以 getShuffleMapStage() 返回为准</p>
<p><code>getShuffleMapStage</code> 首先从 shuffleToMapStage(shuffleid 到 stage 的 map 结构）中查找，没有找到就以 shuffleDep.rdd 为起始点建立一个依赖关系，并且将整条依赖链上的东西都建立起来</p>
<p><code>getAncestorShuffleDependencies</code> 会以一个 RDD 为起点，找到 RDD 直接&amp;间接 依赖的所有 shuffleDependency</p>
<p><code>getAncestorShuffleDependencies</code> 和  <code>getParentStages</code> 类似但又不一样，前者在搜索的时候，每次都需要把 rdd.dep 入队，而后者只需要将 narrowdependency 的入队。还有为什么两个函数一个结果保存为 Set，一个是 Stack？</p>
<p><code>newShuffleMapStage</code> 中会更新 job 和 stage，以及 stage 和 job 的关系，每个 stage 属于哪些 job，每个 job 包含哪些 stage</p>
<p>整个类中有一个变量 <code>mapOutputTracker :MapOutputTracker</code> 用于记录 shuffle 的结果以及位置</p>
<p><code>MapOutputTracker</code> 记录 shuffleMapStage 的 output location  ，为啥要两个 status map（一个 MapStatus，一个 CachedSerializedStatus，后者是前者的序列化之后的结果）,这些 Map 都是带 ttl 的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">/* org.apache.spark.MapOutputTracker.scala</div><div class="line">* Class that keeps track of the location of the map output of</div><div class="line">* a stage. This is abstract because different versions of MapOutputTracker</div><div class="line">* (driver and executor) use different HashMap to store its metadata.</div></pre></td></tr></table></figure>
<p>Driver 使用 MapOutputTrackerMaster 跟踪 output location，只有所有 partition 的 output location 都就绪了，整个被依赖的 RDD 才是就绪的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">* MapOutputTracker for the driver. This uses TimeStampedHashMap to keep track of map</div><div class="line">* output information, which allows old output information based on a TTL.</div></pre></td></tr></table></figure>
<p>Executor 则使用 <code>MapOutputTrackerWorker</code> 从 Driver 获取 map output 的相应信息</p>
<p><code>newOrUsedShuffleStage</code> 函数中首先查找该 shuffleMapStage 是否注册过 MapOutputTracker，如果注册过就直接获取，如果没有注册过就进行注册。<br>MapOutputTracker 有两个 Map 结构，一个是原始的 partition location，一个是序列化之后的（用于加速？），这两个 map 包含过期清理策略，用于节省空间</p>
<p>定期清理的 Meta 信息包括如下几种：</p>
<ul>
<li>MAP_OUTPUT_TRACKER, </li>
<li>SPARK_CONTEXT, </li>
<li>HTTP_BROADCAST, </li>
<li>BLOCK_MANAGER,</li>
<li>SHUFFLE_BLOCK_MANAGER, </li>
<li>BROADCAST_VARS</li>
</ul>
<h3 id="上面是一条链路上的相关函数，下面包括一些其他的处理"><a href="#上面是一条链路上的相关函数，下面包括一些其他的处理" class="headerlink" title="上面是一条链路上的相关函数，下面包括一些其他的处理"></a>上面是一条链路上的相关函数，下面包括一些其他的处理</h3><h4 id="handleTaskCompletion-处理-Task-comple-的信息（不分成功和失败）"><a href="#handleTaskCompletion-处理-Task-comple-的信息（不分成功和失败）" class="headerlink" title="handleTaskCompletion 处理 Task comple 的信息（不分成功和失败）"></a><code>handleTaskCompletion</code> 处理 Task comple 的信息（不分成功和失败）</h4><p>task complete 会分几种信息：</p>
<ul>
<li><p>Success：<br>首先将 task 从 pendingTask 中去掉<br>  task 分为两种：</p>
<ul>
<li>ResultTask：<br>将 job 对应的当前 task 标记为 true（如果没有标记过的话），如果整个 job 都处理完成，就将 stage 标记为完成</li>
<li><p>ShuffleMapTask：<br>更新 outputLocation （当前 shuffleMapTask 的输出）<br>如果 ShuffleMapTask 的所有 partition 都处理完成，就将当前的 stage 标记为完成<br>这里为了防止是重复进行计算（之前失败过），需要重新进行 outputLocation 的注册（主要是增加 epoch）<br>如果当前当前的 Stage.isAvailable 为 true 就通知所有依赖该 stage 的 stage 可以继续工作了。否则重新提交失败的 task（注意这里available 和上面的 finish 不一样，available 是以 output 是否能够获取到为准）</p>
</li>
<li><p>Resubmitted：<br>将 task 加到 pendingTask 中即可，等待后续的调度</p>
</li>
<li><p>FetchFailed：<br>首先判断失败 task 的 attemp 是否是当前的 attemp，不是就忽略，然后判断当前 stage 是否正在运行，如果不是，忽略。<br>否则将当前的 stage 标记为 finish，然后将进行 mapStage.removeOutputLoc 以及 mapOutputTracker.unregisterMapOutput。<br>如果同一个 executor 上的 fetchFailed 很多（这个有调用方判断），则将所在的 executor 标记为 Failed</p>
</li>
<li><p>其他信息，直接忽略</p>
</li>
</ul>
</li>
</ul>
<h4 id="ExecutorLost"><a href="#ExecutorLost" class="headerlink" title="ExecutorLost"></a>ExecutorLost</h4><p>如果上报的 executor 之前没有上报过（会有一个 Map 记录所有上报过的 executor），或者之前上报的该 executor 对应的 epoch 小于 currentepoch， 则需要进行处理</p>
<p>首先从 blockManagerMaster 中将当前 executor 删除</p>
<p>如果没有启动 externalShuffleService（开启 <code>DynamicAllocation</code> 后需要开启，不然会出问题），或者 fetchFailed（由调用方设置），则进行下面的操作：</p>
<p><code>if (!env.blockManager.externalShuffleServiceEnabled || fetchFailed)</code></p>
<p>所该 executor 上所有的输出都进行标记删除，并且增加 <code>mapOutputTracker</code> 的 epoch</p>
<h4 id="ExecutorAdded"><a href="#ExecutorAdded" class="headerlink" title="ExecutorAdded"></a>ExecutorAdded</h4><p>  如果当前添加的 executor 是马上需要回收的，那么就从即将回收的 map 中删除，防止回收，否则不需要操作</p>
<h4 id="StageCancellation"><a href="#StageCancellation" class="headerlink" title="StageCancellation"></a>StageCancellation</h4><p>  如果有正在运行的 job 依赖当前 stage，则将所有的 job 标记为 cancel</p>
<h4 id="JobCancellation"><a href="#JobCancellation" class="headerlink" title="JobCancellation"></a>JobCancellation</h4><p>  将该 job 以及只由该 job 依赖的 stage 都标记为 failed</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>  <code>spark.stage.maxConsecutiveAttempts</code> 表示一个 stage 尝试多少次之后会被标记为失败</p>
<p>  SparkContext 中会根据模式生成和注册相应的 backend 以及 taskscheduler</p>
<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><ol>
<li>如果一个 Stage 有多个 RDD，那么这些 RDD 是在同一个 TaskSet 中吗</li>
<li>如何模拟 <code>r2 = r0.reduceByKey; r3 = r1.reduceByKey; r4 = r2.map(xx); r5 = r4.union(r3); r6 = r5.map; r7 = r6.reduceByKey</code> 的 Stage 划分和生成（会有多少个 Stage，每个 Stage 分别包含哪些 RDD，以及整个 DAG 怎么整合起来的）</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/10/16/spark-dagscheduler/" data-id="cja5d8i3u0002eufypha6xjcn" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dagscheduler/">dagscheduler</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/partition/">partition</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/rdd/">rdd</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/source-code/">source_code</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/">spark</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/stage/">stage</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/10/22/hello-world/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Hello World
        
      </div>
    </a>
  
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/dagscheduler/">dagscheduler</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/partition/">partition</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/rdd/">rdd</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/source-code/">source_code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/spark/">spark</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/stage/">stage</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/dagscheduler/" style="font-size: 10px;">dagscheduler</a> <a href="/tags/partition/" style="font-size: 10px;">partition</a> <a href="/tags/rdd/" style="font-size: 10px;">rdd</a> <a href="/tags/source-code/" style="font-size: 10px;">source_code</a> <a href="/tags/spark/" style="font-size: 10px;">spark</a> <a href="/tags/stage/" style="font-size: 10px;">stage</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/10/22/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2017/10/16/spark-dagscheduler/">spark_dagscheduler</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>